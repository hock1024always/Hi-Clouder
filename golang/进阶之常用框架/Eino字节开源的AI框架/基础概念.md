# 基础概念

在了解后端就业前景的时候，一个前辈给了使用AI搭建应用程序的实践建议，接下来的几天我将按照基础概念了解、字节开源的`Eino`开发框架学习、项目实际开发、工程问题分析和场景设计这套流程进行AI应用开发的学习

# Generative AI

生成式人工智能，是我们了解使用LLM并且进行AI应用开发的最基础概念。

## 基础模型

LLMs的基础概念是`Foundation Models`（基础模型）。在传统AI开发中，通常需要为每个特定任务（task-specific）训练独立的专用模型，而基础模型代表了一种新范式：通过**单一通用模型**的海量预训练，取代了传统针对不同任务的碎片化模型库。

这种范式下的基础模型，通过**自监督学习**（如预测下一个词）在大量数据（包括非结构化文本、代码等）上训练，获得通用能力。它能够适配多种下游任务（如问答、翻译），而无需针对每个任务从头训练。其中，**具备生成能力**的基础模型（如GPT），能够基于输入内容预测并生成后续文本（或图像、代码等），这类模型被称为生成式人工智能（Generative AI），属于基础模型的一个重要分支。不同于特定模型从零开始，针对单一任务（如情绪分类）用标注数据直接训练，基础模型自监督性学习的目标是掌握通用语言/视觉等能力，而非解决具体任务。

我简单举一个训练一个能够识别语句情绪的基础模型的例子，首先需要收集大量带有情绪标签的文本数据（如影评、社交媒体帖子等），然后选择一个预训练好的基础模型（如BERT或GPT），通过微调的方式让模型学习情绪分类任务：在保持原有语言理解能力的同时，使用标注数据调整模型参数，使其能够准确判断输入文本的情绪倾向（如积极、消极或中性）。最终模型既能理解通用语言特征，又具备专业的情绪识别能力。

基础模型从训练初期就走了一条"先通才，后专才"的路径，其核心价值在于通过预训练建立通用理解能力，再灵活迁移到下游任务，这与直接训练特定任务的模型有根本性差异。

## 训练

如果在训练模型时，在等式中运入少量标记数据，可以调整它们执行传统的NLP任务（分类或者命名实体识别）。上面的例子被称为**调优（tuning）**，通过引入少量数据来调整基础模型，更新模型参数，然后执行非常具体的自然语言任务。

只有少量数据点，采用这样的模型可以在低签领域通过设计输入文本（提示词/Prompt）来引导模型生成 desired 的输出，**无需重新训练模型**，这种形式被称为提示词工程。

| 维度             | 调优（Fine-tuning） | 提示词工程（Prompt Engineering） |
| :--------------- | :------------------ | :------------------------------- |
| **是否需要训练** | 需要                | 不需要                           |
| **数据需求**     | 大量标注数据        | 无需数据（但需设计技巧）         |
| **成本**         | 高（算力、时间）    | 低（仅人工设计）                 |
| **灵活性**       | 修改需重新训练      | 可即时调整Prompt                 |
| **效果上限**     | 通常更高            | 受限于预训练模型                 |

## 优势与不足

基础模型这种训练方式的优势主要有以下两点：

1. 性能表现上很好，大量的数据训练使得基础模型的表现优于在几个数据点上训练处的特定模型
2. 生产力提高，经过prompting或者tuning，所需标签数少了很多

同时，主要缺点也有下面两点：

1. 基础模型训练成本高，需要数据集数据量大，推理运行如此大量数据也很昂贵
2. 信任性问题，大量数据很多无法被严格筛选与标注、使用开源模型很多时候原有参数无法保证可信性

# Prompt Agent MCP `FunctionCalling`

## Prompt

我们来拿聊天AI举例，当我向`kimi`问一句“你好”的时候，这句“你好”被称为用户提示词（user prompt）。

而在一些对话应用中，用户是可以选择偏好的，比如语言风格或者一些其他习惯，这部分信息会存储在系统提示词（system prompt）中

用户提示词和系统提示词会打包发给AI模型

## Agent

Agent被称为智能体，我觉得更形象的翻译应该是“代理”。

最早的一款agent是`AutoGPT`，是一款安装在本地的agent程序。用户需要自己准备一些工具，如查看文件目录、修改文件目录等等的脚本，以方便其使用，这些脚本的位置和使用方式存储在system-prompt里面，和用户的需求（比如删除原神）一起发给AI模型，AI模型会将如何调用怎么做返回给Agent，重复这个过程直到任务完成。

在Agent和AI模型对话的过程中，存在AI模型出现幻觉的问题，这个时候最直接的方法就是重新将问题问给模型，直到回答出想要的答案

## `FunctionCalling`

在调用AI模型时，单纯的重复可能会造成随机性延时以及token消耗过多的情况，因此使用`functioncalling`取代系统提示词的规范形式。`functioncalling`规范了Agent询问和AI模型回答的格式，一般将某个工具的信息、使用方式存储在一个`json`文本中，这些文本统一放在一个地方并且和User-Prompt一起发给模型。模型回复的信息也规定了格式，如果出现幻觉模型可以自行纠正。

## MCP

和`functioncalling`有异曲同工之妙的MCP规定了Agent调用工具的规范协议。

此前，这些工具一般和Agent放在一个应用程序中运行，但是为了提高效率以及跨机运行（本机使用io、跨机使用http），使用MCP协议进行解耦，这些工具被统称为“MCP Server” 而调用他们的Agent被称为“MCP Client”，MCP规范了Server要提供的接口类型以及规范格式，Server提供了工具、提示词模板和资源。

下面就是用户请求，Agent处理，模型处理的一个基本流程

![image-20250801023455744](../图片/Agent.png)

# Transformer





# vibe coding/cursor







# agentic AI workflow， dify，n8n







# Cline ， vscode的plugin







# RAG， finetuning，







# vectorDB







# cuda







