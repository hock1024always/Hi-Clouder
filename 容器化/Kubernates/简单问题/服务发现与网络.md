# 1. 简述 Kubernetes Service 类型？

**思路**：

列举四种标准类型，说明各自用途和适用场景。

**回答**：

Kubernetes Service 有四种类型：

- **ClusterIP**（默认）：分配一个集群内部虚拟 IP，仅在集群内访问；
- **NodePort**：在每个节点开放固定端口（30000–32767），外部可通过 `<NodeIP>:<Port>` 访问；
- **LoadBalancer**：云厂商自动创建外部负载均衡器（如阿里云 SLB、腾讯云 CLB），并将流量转发到后端 Pod；
- **ExternalName**：通过 CNAME 将服务映射到外部 DNS 名称（不涉及 Pod，用于集成外部服务）。

------

# 2. 简述 Kubernetes Service 分发后端的策略？

**思路**：

说明 kube-proxy 支持的两种负载均衡算法。

**回答**：

Service 默认使用 **随机（Random）** 算法分发流量到后端 Pod。
 若启用 **SessionAffinity（会话保持）** 为 `ClientIP`，则相同客户端 IP 在一定时间内（默认 10800 秒）始终路由到同一 Pod。

> 注意：该策略由 kube-proxy 实现，与底层 iptables/IPVS 无关。

------

# 3. 简述 Kubernetes Headless Service？

**思路**：

强调“无 ClusterIP”、“直接暴露 Pod DNS”，用于有状态服务发现。

**回答**：

Headless Service 是将 `spec.clusterIP` 设为 `None` 的 Service，**不分配虚拟 IP**，也不进行负载均衡。其作用是：

- 为 Pod 提供**稳定的 DNS 记录**（如 `pod-name.service-name.namespace.svc.cluster.local`）；
- 客户端可直接解析到所有后端 Pod IP 列表，自行选择连接（常用于 StatefulSet 场景，如 ZooKeeper、Kafka）；
- 支持按 Pod 名称进行精确寻址，满足有状态应用的拓扑感知需求。

------

# 4. 简述 kube-proxy 作用？

**思路**：

定位为“节点级网络代理”，实现 Service 的流量转发。

**回答**：

kube-proxy 运行在每个 Worker 节点上，负责**实现 Kubernetes Service 的网络代理和负载均衡**。它监听 API Server 中 Service 和 Endpoints 的变化，并在本机配置规则（iptables 或 IPVS），将发往 Service ClusterIP/NodePort 的流量转发到后端 Pod，确保服务可达性。

------

# 5. 简述 kube-proxy iptables 原理？

**思路**：

说明基于 Netfilter 规则链的 DNAT 转发机制。

**回答**：

kube-proxy 在 iptables 模式下：

- 为每个 Service 和 Endpoint 生成多条 **iptables 规则**；
- 流量到达 Service ClusterIP 时，通过 **PREROUTING → KUBE-SERVICES → KUBE-SVC-xxx → KUBE-SEP-xxx** 链；
- 最终通过 **DNAT** 将目标地址随机替换为某个 Pod IP；
- 优点：无需额外依赖；缺点：规则数随 Service/Pod 增长呈 O(n²)，大规模集群性能下降。

------

# 6. 简述 kube-proxy IPVS 原理？

**思路**：

强调基于内核 IPVS 模块的高效负载均衡。

**回答**：

IPVS 模式下，kube-proxy 调用 Linux 内核的 **IP Virtual Server（IPVS）** 模块：

- 将 Service 视为“虚拟服务器”，Pod 为“真实服务器”；
- 使用哈希表管理转发规则，支持多种调度算法（rr、lc、dh、sh 等）；
- 性能远高于 iptables，尤其在大规模 Service 场景（万级）；
- 需节点内核启用 IPVS 模块（`ip_vs` 系列模块）。

------

# 7. 简述 kube-proxy IPVS 和 iptables 的异同？

**思路**：

从性能、复杂度、功能、适用规模对比。

**回答**：

| 维度             | iptables                    | IPVS                     |
| ---------------- | --------------------------- | ------------------------ |
| **性能**         | O(n) 规则匹配，大规模性能差 | 哈希表 O(1)，高性能      |
| **负载均衡算法** | 仅随机                      | 支持 rr、lc、dh、sh 等   |
| **依赖**         | 内核默认支持                | 需加载 `ip_vs` 模块      |
| **连接跟踪**     | 依赖 conntrack，易满        | 可关闭 conntrack，更稳定 |
| **适用场景**     | 小规模集群                  | 中大型生产集群（推荐）   |

> 云厂商托管集群（ACK/TKE）默认使用 IPVS。

------

# 8. 简述 Kubernetes 外部如何访问集群内的服务？

**思路**：

按层级列举：NodePort → LoadBalancer → Ingress → HostNetwork/Egress。

**回答**：

外部访问集群服务的主要方式：

1. **NodePort**：通过任意节点 IP + 端口访问；
2. **LoadBalancer**：云厂商自动创建公网 LB，绑定弹性 IP；
3. **Ingress**：七层 HTTP/HTTPS 入口，配合 Ingress Controller（如 Nginx、ALB）实现域名/路径路由；
4. **HostNetwork**：Pod 直接使用宿主机网络（高风险，慎用）；
5. **ExternalIPs**：手动指定 Service 绑定到节点公网 IP（较少用）。

> 生产环境推荐 **LoadBalancer + Ingress** 组合。

------

# 9. 简述 Kubernetes Ingress？

**思路**：

定义为“七层入口网关”，强调需配合 Ingress Controller 使用。

**回答**：

Ingress 是 Kubernetes 的**七层（HTTP/HTTPS）流量入口资源对象**，用于定义基于**域名、路径**的路由规则，将外部请求转发到不同 Service。

- **Ingress 本身不生效**，必须部署 **Ingress Controller**（如 Nginx Ingress、Traefik、云厂商 ALB Controller）；
- 支持 TLS 终止、重写、限流、认证等高级功能；
- 是替代多个 LoadBalancer 的经济高效方案，适合 Web 应用统一接入。

------

# 10. 简述 Kubernetes 网络模型？

**思路**：

引用官方四大原则，强调“扁平网络”和“Pod IP 全局可达”。

**回答**：

Kubernetes 网络模型基于四个核心原则：

1. 所有 Pod 之间**无需 NAT 即可直接通信**；
2. 所有 Node 可与所有 Pod 直接通信；
3. 每个 Pod 的 IP 在集群内**全局唯一且可达**；
4. 容器内看到的 IP 与外部一致（无 NAT）。
   该模型要求 CNI 插件实现**扁平三层网络**（如 Overlay 或 Underlay），确保 Pod 跨节点通信。

------

# 11. 简述 Kubernetes CNI 模型？

**思路**：

说明 CNI 是“容器网络接口标准”，解耦运行时与网络插件。

**回答**：

CNI（Container Network Interface）是 Kubernetes 采用的**容器网络标准规范**，定义了容器运行时（如 containerd）与网络插件之间的调用协议。

- kubelet 在创建 Pod 时调用 CNI 插件（如 Calico、Flannel）；
- CNI 负责为 Pod 分配 IP、配置网络命名空间、设置路由；
- 插件以二进制形式存在 `/opt/cni/bin/`，配置文件在 `/etc/cni/net.d/`；
- 实现网络能力的**可插拔与标准化**。

------

# 12. 简述 Kubernetes 网络策略？

**思路**：

定义为“Pod 级防火墙”，控制入站/出站流量。

**回答**：

NetworkPolicy 是 Kubernetes 的**Pod 级微隔离策略**，用于控制哪些 Pod 可以互相通信。

- 默认“允许所有”，一旦创建 NetworkPolicy，则**仅允许显式放行的流量**；
- 可限制 **ingress（入站）** 和 **egress（出站）**；
- 基于 Pod label、namespace、IP CIDR 等匹配源/目标；
- **需 CNI 插件支持**（如 Calico、Cilium），Flannel 不支持。

------

# 13. 简述 Kubernetes 网络策略原理？

**思路**：

说明其实现依赖 CNI 插件在节点上配置 iptables/eBPF 规则。

**回答**：

NetworkPolicy 本身是声明式 API，**实际执行由 CNI 插件完成**：

- 支持策略的 CNI（如 Calico）会在每个节点监听 NetworkPolicy 变化；
- 动态生成 **iptables 规则** 或 **eBPF 程序**，对进出 Pod 的流量进行过滤；
- 例如：Calico 使用 Felix 组件将策略编译为 iptables chain，实现精细化 ACL 控制；
- 未匹配策略的流量被 DROP，实现零信任安全模型。

------

# 14. 简述 Kubernetes 中 Flannel 的作用？

**思路**：

定位为“简单 Overlay 网络插件”，说明 VXLAN 模式工作原理。

**回答**：

Flannel 是一个轻量级 CNI 插件，用于**为 Kubernetes 集群提供跨节点 Pod 网络通信**。

- 采用 **Overlay 网络**（默认 VXLAN 模式），在物理网络之上封装 Pod 流量；
- 每个节点分配一个子网（如 10.244.1.0/24），Pod IP 从中分配；
- 节点间通过 **VXLAN 封装**（UDP 8472）传输数据包；
- 优点：部署简单；缺点：不支持 NetworkPolicy，性能略低于 Underlay 方案。

------

# 15. 简述 Kubernetes Calico 网络组件实现原理？

**思路**：

强调“纯三层 BGP 路由”或“IPIP/ VXLAN Overlay”，支持 NetworkPolicy。

**回答**：

Calico 是企业级 CNI 插件，支持两种模式：

1. **纯三层（BGP）模式**（推荐）：
   - 每个节点作为 BGP Speaker，向物理路由器宣告 Pod 子网路由；
   - 流量**无需封装**，直接通过三层路由转发，性能高；
2. **IPIP/VXLAN Overlay 模式**：
   - 适用于无法修改底层网络的环境（如公有云），通过 IP-in-IP 或 VXLAN 封装跨节点流量；

- **核心组件**：
  - **Felix**：在节点配置路由和 iptables 策略；
  - **Bird**：实现 BGP 路由分发；
  - **Typha**（可选）：提升大规模集群扩展性；
- **关键优势**：原生支持 **NetworkPolicy**、高性能、可与物理网络集成。